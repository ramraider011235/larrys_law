{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/gdp/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/gdp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finviz import get_news\n",
    "from yahooquery import Ticker\n",
    "from newspaper import Article, Config\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "\n",
    "import src.tools.functions as f0\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download('punkt')\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
    "\n",
    "config = Config()\n",
    "config.browser_user_agent = user_agent\n",
    "config.request_timeout = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = '2022-07-28'\n",
    "month1 = str(day1)[:7]\n",
    "year1 = str(day1)[:4]\n",
    "now = dt.date.today()\n",
    "now = now.strftime('%m-%d-%Y')\n",
    "yesterday = dt.date.today() - dt.timedelta(days = 3)\n",
    "yesterday = yesterday.strftime('%m-%d-%Y')\n",
    "\n",
    "saveRaw = Path(f\"/home/gdp/hot_box/larrys_law/data/raw/{month1}/{day1}/\")    \n",
    "sentiment = Path(f\"/home/gdp/hot_box/larrys_law/data/sentiment/sentiment/{year1}/{month1}/{day1}/\")    \n",
    "single_news = Path(f\"/home/gdp/hot_box/larrys_law/data/sentiment/single_news/{year1}/{month1}/{day1}/\")    \n",
    "saveRec = Path(f\"/home/gdp/hot_box/larrys_law/data/recommenders/{year1}/{month1}/{day1}/\")\n",
    "bulk_data_file = Path(f\"/home/gdp/hot_box/larrys_law/data/finviz/{month1}/{day1}/finviz.csv\")\n",
    "\n",
    "if not saveRaw.exists():\n",
    "    saveRaw.mkdir(parents=True)\n",
    "if not sentiment.exists():\n",
    "    sentiment.mkdir(parents=True)   \n",
    "if not single_news.exists():\n",
    "    single_news.mkdir(parents=True)           \n",
    "if not saveRec.exists():\n",
    "    saveRec.mkdir(parents=True)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_data_0():\n",
    "    data_0 = pd.read_csv(bulk_data_file).round(4).fillna(0.001)\n",
    "    data_0 = pd.DataFrame(f0.clean_sort(data_0))\n",
    "    data_0.to_pickle(saveRec / \"larry_finviz.pkl\")\n",
    "    print(\"[0] Bulk Data:\")\n",
    "    print(f\"---> Total Stock Count: {data_0.shape} \\n\")\n",
    "    return data_0    \n",
    "\n",
    "\n",
    "\n",
    "def source_data_1():\n",
    "    data_0 = source_data_0()\n",
    "    data = pd.DataFrame(data_0)\n",
    "    print(f\"[1] Market Cap\")\n",
    "\n",
    "    mkt_cap_min = 750000000\n",
    "    mkt_cap_max = 2500000000\n",
    "    data['market_cap'] = data['market_cap'] * 1000000\n",
    "\n",
    "    data = data[data['market_cap'] >= mkt_cap_min]\n",
    "    data = data[data['market_cap'] <= mkt_cap_max]\n",
    "    data['market_cap'] = [f\"${x:,.2f}\" for x in list(data['market_cap'])]\n",
    "    print(f\"---> Stocks With BOTH (Market Cap < ${mkt_cap_max:,.2f}) & (Market Cap > ${mkt_cap_min:,.2f}): {data.shape}\")\n",
    "\n",
    "    \n",
    "    # data = data[data['analyst_recom'] != 0.001]\n",
    "    # print(f\"---> Stocks With an Average Analyst Recom: {data.shape}\") \n",
    "    \n",
    "    # data = data[data['analyst_recom'] <= 3.0]\n",
    "    # print(f\"---> Average Analyst Recom == of [STRONG-BUY(1), BUY(2), HOLD(3)]: {data.shape}\")\n",
    "    \n",
    "    # data = data[data['target_price'] != 0.0]\n",
    "    # print(f\"---> Stocks With A target_price: {data.shape}\")\n",
    "    \n",
    "    # data = data[data['target_price'] >= data['price']]\n",
    "    # print(f\"---> target_price > price: {data.shape}\")    \n",
    "    \n",
    "    # data = data[data['eps_growth_quarter_over_quarter'] >= 0.0]\n",
    "    # print(f\"---> eps_growth_quarter_over_quarter > 0.0: {data.shape}\")\n",
    "    \n",
    "    # data = data[data['sales_growth_quarter_over_quarter'] >= 0.0]\n",
    "    # print(f\"---> sales_growth_quarter_over_quarter > 0.0: {data.shape}\")    \n",
    "    \n",
    "    # data = data[data['operating_margin'] > 0.0]\n",
    "    # print(f\"---> operating_margin > 0.0: {data.shape}\")     \n",
    "        \n",
    "    data.to_pickle(saveRec / \"larry_recommender_01_return_dataFrame.pkl\")\n",
    "    return data_0, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Bulk Data:\n",
      "---> Total Stock Count: (8558, 67) \n",
      "\n",
      "[1] Market Cap\n",
      "---> Stocks With BOTH (Market Cap < $2,500,000,000.00) & (Market Cap > $750,000,000.00): [[(1122, 67)]]\n"
     ]
    }
   ],
   "source": [
    "data_0, data_1 = source_data_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "\n",
    "\n",
    "def fte(stocks):\n",
    "    fte_list = []\n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            yqT = Ticker(stock)\n",
    "            x = pd.DataFrame(yqT.asset_profile)\n",
    "            y = float(x[x.index == 'fullTimeEmployees'][f\"{stock}\"][0])\n",
    "            fte_list.append(y)\n",
    "        except Exception:\n",
    "            fte_list.append(0)\n",
    "    return fte_list\n",
    "\n",
    "\n",
    "def revenue(stocks):\n",
    "    list1 = []\n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            yqT = Ticker(stock)\n",
    "            x = yqT.income_statement(frequency='a').iloc[-1]['TotalRevenue']\n",
    "            list1.append(round(float(x),2))\n",
    "        except Exception:\n",
    "            list1.append(0)\n",
    "    return list1    \n",
    "\n",
    "\n",
    "def run_fte_revenue(stock_tickers):\n",
    "    fte_list = fte(stock_tickers)\n",
    "    revenue_list = revenue(stock_tickers)\n",
    "    return fte_list, revenue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ticker_list = sorted(list(data_1['ticker']))\n",
    "\n",
    "fte_lst, rev_lst = run_fte_revenue(stock_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$38,803.41\n",
      "$38,803,410,000.00\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data_1.copy())\n",
    "\n",
    "df['fte'] = fte_lst\n",
    "df['revenue'] = rev_lst\n",
    "\n",
    "# df['rev_per_fte'] = df['revenue'] / df['fte']\n",
    "\n",
    "# df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# df = df.sort_values('rev_per_fte', ascending=False).fillna(0.0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0['market_cap'] = data_0['market_cap']\n",
    "\n",
    "print(f\"${(amt*1000000):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def technicals_minervini(data):            \n",
    "    rec_02_tickers = list(data[\"ticker\"])      \n",
    "    start_date_101 = dt.date(int(str(day1)[:4]), int(str(day1)[5:7]), int(str(day1)[8:]))\n",
    "    years_ago = str(start_date_101 - relativedelta(years=1, days=69))[:10]\n",
    "                  \n",
    "    exportList = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"ticker\", \n",
    "            \"rs_rating\", \n",
    "            \"returns_multiple\", \n",
    "            \"current_price\", \n",
    "            \"sma_50\", \n",
    "            \"sma_150\", \n",
    "            \"sma_200\", \n",
    "            \"sma_200_20\", \n",
    "            \"low_52_week\", \n",
    "            \"high_52_week\"\n",
    "        ]\n",
    "    )    \n",
    "    \n",
    "\n",
    "    # Index Returns\n",
    "    index_name = '^GSPC'\n",
    "    if exists(saveRaw / \"sp500_index.pkl\"):\n",
    "        index_df = pd.DataFrame(pd.read_pickle(saveRaw / \"sp500_index.pkl\"))\n",
    "        index_df[\"pct_change\"] = index_df[\"Adj Close\"].pct_change()\n",
    "        index_return = (index_df[\"pct_change\"] + 1).cumprod()[-1]\n",
    "    elif not exists(saveRaw / \"sp500_index.pkl\"):\n",
    "        index_df = pd.DataFrame(yf.download(index_name, start='2021-07-01', end=day1))\n",
    "        index_df.to_pickle(saveRaw / \"larry_sp500_index.pkl\")\n",
    "        index_df[\"pct_change\"] = index_df[\"Adj Close\"].pct_change()\n",
    "        index_return = (index_df[\"pct_change\"] + 1).cumprod()[-1]\n",
    "\n",
    "\n",
    "    def source_hist(ticker_list):\n",
    "        bad_list = []\n",
    "        for ticker in ticker_list:\n",
    "            if exists(saveRaw / f\"{ticker}.pkl\"):\n",
    "                pass\n",
    "            else:\n",
    "                bad_list.append(ticker)\n",
    "        return bad_list    \n",
    "    \n",
    "    def import_history(port_tics1):                               \n",
    "        tickers = Ticker(port_tics1, asynchronous=True)\n",
    "        df3 = pd.DataFrame(tickers.history(start=years_ago, end=day1))\n",
    "        for s in port_tics1:\n",
    "            try:\n",
    "                df = pd.DataFrame(df3.T[s].T[['adjclose', 'high', 'low']][1:])\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df.to_pickle(saveRaw / f\"larry_{s}.pkl\")\n",
    "            except:\n",
    "                print(f\"failed ticker {s}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Find top 50% performing stocks (relative to the S&P 500)\n",
    "    bad_list = source_hist(rec_02_tickers)  \n",
    "    if bad_list:\n",
    "        import_history(bad_list)        \n",
    "\n",
    "    returns_multiples = []\n",
    "    for ticker in rec_02_tickers:\n",
    "        # Calculating returns relative to the market (returns multiple)      \n",
    "        try:\n",
    "            df = pd.DataFrame(pd.read_pickle(saveRaw / f\"{ticker}.pkl\"))\n",
    "            df[\"pct_change\"] = df[\"adjclose\"].pct_change()\n",
    "            stock_return = (df[\"pct_change\"] + 1).cumprod()[-1]\n",
    "            returns_multiple = round((stock_return / index_return), 2)\n",
    "            returns_multiples.extend([returns_multiple])\n",
    "        except Exception:\n",
    "            print(f\"Bad Ticker: {ticker}\")\n",
    "         \n",
    "    # Creating dataframe of only top 70%\n",
    "    rs_df = pd.DataFrame(list(zip(rec_02_tickers, returns_multiples)),columns=[\"ticker\", \"returns_multiple\"],)\n",
    "    rs_df[\"rs_rating\"] = rs_df[\"returns_multiple\"].rank(pct=True) * 100\n",
    "    rs_df = rs_df[rs_df[\"rs_rating\"] >= rs_df[\"rs_rating\"].quantile(0.3)]\n",
    "    \n",
    "    \n",
    "    # Checking Minervini conditions of top 60% of stocks in given list\n",
    "    rs_stocks = list(rs_df[\"ticker\"])\n",
    "    for stock in rs_stocks:\n",
    "        try:     \n",
    "            df = pd.DataFrame(pd.read_pickle(saveRaw / f\"{stock}.pkl\"))\n",
    "            sma = [50, 150, 200]\n",
    "            for x in sma:\n",
    "                df[\"SMA_\" + str(x)] = round(df[\"adjclose\"].rolling(window=x).mean(), 2)\n",
    "            # Storing required values\n",
    "            currentClose = df[\"adjclose\"].iloc[-1]\n",
    "            MA_50 = df[\"SMA_50\"].iloc[-1]\n",
    "            MA_150 = df[\"SMA_150\"].iloc[-1]\n",
    "            MA_200 = df[\"SMA_200\"].iloc[-1]\n",
    "            low_52_week = round(min(df[\"low\"][-260:]), 2)\n",
    "            high_52_week = round(max(df[\"high\"][-260:]), 2)\n",
    "            RS_Rating = round(rs_df[rs_df[\"ticker\"] == stock].rs_rating.tolist()[0], 2)\n",
    "            Returns_multiple = round(\n",
    "                rs_df[rs_df[\"ticker\"] == stock].returns_multiple.tolist()[0], 2)\n",
    "            try:\n",
    "                MA_200_20 = df[\"SMA_200\"][-20]\n",
    "            except Exception:\n",
    "                MA_200_20 = 0\n",
    "                        \n",
    "        # Condition 1: Current Price > 150 SMA and > 200 SMA\n",
    "            condition_1 = currentClose > MA_150 > MA_200\n",
    "        # Condition 2: 150 SMA and > 200 SMA\n",
    "            condition_2 = MA_150 > MA_200\n",
    "        # Condition 3: 200 SMA trending up for at least 1 month\n",
    "            condition_3 = MA_200 > MA_200_20\n",
    "        # Condition 4: 50 SMA> 150 SMA and 50 SMA> 200 SMA\n",
    "            condition_4 = MA_50 > MA_150 > MA_200\n",
    "        # Condition 5: Current Price > 50 SMA\n",
    "            condition_5 = currentClose > MA_50\n",
    "        # Condition 6: Current Price is at least 30% above 52 week low\n",
    "            condition_6 = currentClose >= (1.30 * low_52_week)\n",
    "        # Condition 7: Current Price is within 25% of 52 week high\n",
    "            condition_7 = currentClose >= (0.75 * high_52_week)            \n",
    "            \n",
    "        # If all conditions above are true, add Ticker to exportList\n",
    "            if (\n",
    "                condition_1 &\n",
    "                condition_2 &\n",
    "                condition_3 &\n",
    "                condition_4 &\n",
    "                condition_5 &\n",
    "                condition_6 &\n",
    "                condition_7\n",
    "            ):\n",
    "                exportList = exportList.append(\n",
    "                    {\n",
    "                        \"ticker\": stock,\n",
    "                        \"rs_rating\": RS_Rating,\n",
    "                        \"returns_multiple\": Returns_multiple,\n",
    "                        \"current_price\": currentClose,\n",
    "                        \"sma_50\": MA_50,\n",
    "                        \"sma_150\": MA_150,\n",
    "                        \"sma_200\": MA_200,\n",
    "                        \"sma_200_20\": MA_200_20,\n",
    "                        \"low_52_week\": low_52_week,\n",
    "                        \"high_52_week\": high_52_week,\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                ).sort_values(by=\"rs_rating\", ascending=False)             \n",
    "        except Exception:\n",
    "            print(f\"Bad Ticker: {stock}\")\n",
    "\n",
    "    exportList_A = exportList.drop_duplicates(subset=\"ticker\")\n",
    "    exportList_B = exportList_A[exportList_A.rs_rating >= 60.0]\n",
    "    part_a_len = len(exportList_A['ticker'])\n",
    "    part_b_len = len(exportList_B['ticker'])        \n",
    "    \n",
    "    print(\"\\n[2] MINERVINI \")\n",
    "    print(f\"   > PART-A:\")\n",
    "    print(f\"     * Successful Stocks: [{part_a_len}]\")\n",
    "    print(f\"   > PART-B:\")\n",
    "    print(f\"     * Successful Stock WHERE (rs_rating > 60.0): [{part_b_len}] \\n\")\n",
    "    \n",
    "    exportList_B.to_pickle(saveRec / \"larry_recommender_02_return_dataFrame.pkl\")\n",
    "    return exportList_B.round(2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_pickle(saveRec / \"larry_recommender_01_return_dataFrame.pkl\")\n",
    "\n",
    "data_2 = technicals_minervini(data_1)\n",
    "# data_2 = pd.read_pickle((saveRec / \"larry_recommender_02_return_dataFrame.pkl\"))\n",
    "\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_news(stocks):\n",
    "    print(f\"\\nTotal Input Stocks: {len(stocks)} \\n\")\n",
    "    c = 0.0\n",
    "    for stock in stocks:\n",
    "        pkl0 = (single_news / f\"larry_df_single_news_{stock}.pkl\")\n",
    "        col0 = [\"date\", \"title\", \"link\", \"source\"]\n",
    "        msg0 = '[[ COMPLETE ]] - DATA SOURCED AND SAVED -[SUCCESSFUL]'\n",
    "        c += 1\n",
    "        if exists(pkl0):\n",
    "            print(f\"[{c}] - {stock} - COMPLETE - {stock} DATA ON FILE\")\n",
    "        else:\n",
    "            try: \n",
    "                data_news = get_news(stock)\n",
    "                df_news = pd.DataFrame((data_news), columns=col0)\n",
    "                df_news = df_news.loc[:30]\n",
    "                df_news = df_news[df_news['date'] > '2022-05']\n",
    "                df_news = df_news[df_news['date'] <= day1]\n",
    "                df_news.to_pickle(pkl0)\n",
    "                print(f\"[{c}] - {stock} - {msg0}\")\n",
    "            except:\n",
    "                print(f\"BAD TICKER {stock} 5\")\n",
    "                stocks.remove(stock)\n",
    "    return stocks\n",
    "\n",
    "\n",
    "def process_news(stocks):\n",
    "    final_stocks = []\n",
    "    c = 0.0\n",
    "    for stock in stocks:\n",
    "        c += 1\n",
    "        print(f\"\\n[ {int(c)} / {int(len(stocks))} ] - {stock}\")\n",
    "        pkl1 = (single_news / f\"larry_df_single_news_{stock}.pkl\")\n",
    "        pkl2 = (single_news / f\"larry_df_single_news_full{stock}.pkl\")\n",
    "        if exists(pkl2):\n",
    "            final_stocks.append(stock)\n",
    "            print(f\"[X] - DONE - {stock}\")\n",
    "        else:\n",
    "            try:\n",
    "                df = pd.DataFrame(pd.read_pickle(pkl1))\n",
    "                list =[]                                                          # creating an empty list\n",
    "                for i in df.index:\n",
    "                    dict = {}                                                     # create empty dictionary to add articles\n",
    "                    article = Article(df['link'][i], config=config)               # providing the link\n",
    "                    try:\n",
    "                        article.download()                                        # downloading the article \n",
    "                        article.parse()                                           # parsing the article\n",
    "                        article.nlp()                                             # performing natural language processing\n",
    "                    except:                                                       # exception handling\n",
    "                        print('error stock download')\n",
    "                    dict['date']=df['date'][i]                                    # storing results in dictionary from above\n",
    "                    dict['source']=df['source'][i] \n",
    "                    dict['title']=article.title\n",
    "                    dict['article']=article.text\n",
    "                    dict['summary']=article.summary\n",
    "                    dict['key_words']=article.keywords\n",
    "                    dict['link']=df['link'][i]\n",
    "                    list.append(dict)\n",
    "                check_empty = not any(list)\n",
    "                if check_empty == False:\n",
    "                    try:\n",
    "                        news_df=pd.DataFrame(list)                                # creating dataframe\n",
    "                        p1 = (pkl2)\n",
    "                        news_df.to_pickle(p1)\n",
    "                        final_stocks.append(stock)\n",
    "                        print(f\"[X] - DONE - {stock}\")                            # exception handling\n",
    "                    except Exception:\n",
    "                        print('error save')\n",
    "            except Exception as e:                                                # exception handling\n",
    "                print(\"Exception:\" + str(e))\n",
    "    return final_stocks\n",
    "\n",
    "\n",
    "def sentiment_analysis(newS, stocks):\n",
    "    for stock in stocks:               \n",
    "        (\n",
    "            dates, \n",
    "            sources, \n",
    "            titles, \n",
    "            articles, \n",
    "            summarys, \n",
    "            key_words, \n",
    "            links\n",
    "        ) = (\n",
    "            newS['date'], \n",
    "            newS['source'], \n",
    "            newS['title'], \n",
    "            newS['article'], \n",
    "            newS['summary'], \n",
    "            newS['key_words'], \n",
    "            newS['link']\n",
    "        )\n",
    "        parsed_news=[]\n",
    "        for r in range(len(newS)):\n",
    "            parsed_news.append(\n",
    "                [\n",
    "                    \n",
    "                    stock, \n",
    "                    dates[r], \n",
    "                    sources[r], \n",
    "                    titles[r], \n",
    "                    articles[r], \n",
    "                    summarys[r], \n",
    "                    key_words[r], \n",
    "                    links[r]\n",
    "                ]\n",
    "            )\n",
    "        columns = [\n",
    "            \"ticker\", \n",
    "            \"date\", \n",
    "            'source', \n",
    "            \"title\", \n",
    "            'article', \n",
    "            'summary', \n",
    "            'key_words', \n",
    "            \"link\"\n",
    "        ]\n",
    "    # Sentiment Analysis\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        news = pd.DataFrame(parsed_news, columns=columns).dropna()       \n",
    "        scores = news[\"summary\"].apply(analyzer.polarity_scores).tolist()        \n",
    "        df_scores = pd.DataFrame(scores)\n",
    "        news = news.join(df_scores, rsuffix=\"_right\")     \n",
    "    # View Data\n",
    "        news[\"date\"] = pd.to_datetime(news['date']).dt.date\n",
    "        unique_ticker = news[\"ticker\"].unique().tolist()\n",
    "        news_dict = {\n",
    "            name: news.loc[news[\"ticker\"] == name] for name in unique_ticker\n",
    "            }\n",
    "        values = []\n",
    "    for stock in stocks:\n",
    "        dataframe = news_dict[stock]\n",
    "        dataframe = dataframe.set_index(\"ticker\")\n",
    "        mean = round(dataframe[\"compound\"].mean() * 100, 0)\n",
    "        values.append(mean)\n",
    "    df = pd.DataFrame(stocks, columns=[\"ticker\"])\n",
    "    df[\"sentiment_score\"] = values\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_sentiment(stocks):\n",
    "    df = pd.DataFrame()\n",
    "    symbols = []\n",
    "    sentiments = []\n",
    "    bad_stocks = []\n",
    "    for stock in stocks:\n",
    "        pkl3 = (single_news / f\"larry_df_single_news_full{stock}.pkl\")\n",
    "        pkl4 = (sentiment / f\"larry_{stock}_sentiment.pkl\")        \n",
    "        try:           \n",
    "            newS = pd.read_pickle(pkl3)\n",
    "            fd = sentiment_analysis(newS, [stock])\n",
    "            symbols.append(fd[\"ticker\"].loc[0])\n",
    "            sentiments.append(fd[\"sentiment_score\"].loc[0])\n",
    "            fd.to_pickle(pkl4)\n",
    "        except Exception:\n",
    "            print(f\"BAD TICKER {stock} 4\")\n",
    "            stocks.remove(stock)\n",
    "            bad_stocks.append(stock)\n",
    "    df[\"ticker\"] = symbols\n",
    "    df[\"sentiment_score\"] = sentiments\n",
    "    return df, bad_stocks\n",
    "\n",
    "\n",
    "def run_rec_3(rec_03_tickers):             \n",
    "    df_final, bad_stocks = run_sentiment(rec_03_tickers)\n",
    "    df_final = df_final[df_final['sentiment_score'] >= 0.0]\n",
    "    fin_len = len(df_final['ticker'])\n",
    "    pkl4 = saveRec / \"larry_recommender_03_return_dataFrame.pkl\"\n",
    "    df_final.to_pickle(pkl4)\n",
    "    print(f\"[3] Sentiment Analysis - Successful Securities = [{fin_len}]]\")\n",
    "    return df_final.sort_values('sentiment_score', ascending=False), bad_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_pickle(saveRec / \"larry_recommender_02_return_dataFrame.pkl\")\n",
    "sentiment_ticker_list = list(data_2['ticker'])\n",
    "\n",
    "sentiment_news_tickers = mini_news(sentiment_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_news_tickers = process_news(sentiment_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3, bad_stocks = run_rec_3(sentiment_news_tickers)\n",
    "print(f\"Bad Stocks: {len(bad_stocks)}\")\n",
    "data_3 = pd.DataFrame(data_3).sort_values('sentiment_score', ascending=False)\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rec_4(rec_final_01, rec_final_02, rec_final_03):            \n",
    "\n",
    "\n",
    "    def fix_rec_01(rec_final_01):\n",
    "        rec_final_01 = pd.DataFrame(rec_final_01)\n",
    "        rec_final_01.columns = [x.lower() for x in rec_final_01.columns]\n",
    "        rec_final_01 = rec_final_01.rename(columns={\"analyst_recom\": \"ar\"})\n",
    "        ar = [\n",
    "            3.0, 2.9, 2.8, 2.7, 2.6, 2.5, 2.4, 2.3, 2.2, 2.1, \n",
    "            2.0, 1.9, 1.8, 1.7, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1.0\n",
    "            ]\n",
    "        analyst_recom = list(np.arange(50.0, 101.0, 2.5).round())\n",
    "        d1 = dict(zip(ar, analyst_recom))\n",
    "        adj__analyst_lst = []\n",
    "        for i in rec_final_01[\"ar\"]:\n",
    "            for key, val in d1.items():\n",
    "                if i == key:\n",
    "                    adj__analyst_lst.append(val)\n",
    "        del rec_final_01[\"ar\"]\n",
    "        rec_final_01[\"analyst_recom\"] = adj__analyst_lst            \n",
    "        return rec_final_01\n",
    "\n",
    "\n",
    "    def fix_rec_02(rec_final_02):\n",
    "        rec_final_02 = pd.DataFrame(rec_final_02)\n",
    "        rec_final_02.columns = [x.lower() for x in rec_final_02.columns]\n",
    "        del rec_final_02['sma_50']\n",
    "        del rec_final_02['sma_200']\n",
    "        del rec_final_02['low_52_week']\n",
    "        del rec_final_02['high_52_week']\n",
    "        rec_final_02 = rec_final_02.round(2)\n",
    "        return rec_final_02    \n",
    "    \n",
    "\n",
    "    def fix_rec_03(rec_final_03):\n",
    "        rec_final_03 = pd.DataFrame(rec_final_03)\n",
    "        rec_final_03.columns = [x.lower() for x in rec_final_03.columns]\n",
    "        return rec_final_03   \n",
    "    \n",
    "\n",
    "    def merge_dataframes(rec_01, rec_02, rec_03):\n",
    "        rec_01 = pd.DataFrame(rec_01[rec_01[\"ticker\"].isin(list(rec_03[\"ticker\"]))])\n",
    "        rec_02 = pd.DataFrame(rec_02[rec_02[\"ticker\"].isin(list(rec_03[\"ticker\"]))])\n",
    "        a = pd.DataFrame(rec_01.merge(rec_02, how=\"inner\", on=\"ticker\"))\n",
    "        b = a.merge(rec_03, how=\"inner\", on=\"ticker\")   \n",
    "        final_df = pd.DataFrame(b.copy())\n",
    "        return final_df\n",
    "    \n",
    "\n",
    "    def create_new_cols(df):\n",
    "        df[\"my_score\"] = (\n",
    "            ((df[\"analyst_recom\"]) + (df[\"rs_rating\"]) + (df[\"sentiment_score\"])) / 3\n",
    "            )\n",
    "        return df   \n",
    "\n",
    "\n",
    "    def finish_stage_4(final_len):\n",
    "        final_len = len(final_df['ticker'])\n",
    "        final_df.to_pickle(saveRec / \"larry_recommender_04_return_dataFrame.pkl\")\n",
    "        print(f'[4] Recommender Stage #04 - [Total Passed == {final_len}]')        \n",
    "        \n",
    "    \n",
    "    rec_final_01 = fix_rec_01(rec_final_01)\n",
    "    rec_final_02 = fix_rec_02(rec_final_02)\n",
    "    rec_final_03 = fix_rec_03(rec_final_03)\n",
    "    final_df0 = merge_dataframes(rec_final_01, rec_final_02, rec_final_03)\n",
    "    final_df = create_new_cols(final_df0)\n",
    "    finish_stage_4(final_df)    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.DataFrame(run_rec_4(data_1, data_2, data_3))\n",
    "print(df_4.shape)\n",
    "df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rec_5(data):\n",
    "\n",
    "\n",
    "    def re_order_cols(fd):          \n",
    "        fd = pd.DataFrame(fd)\n",
    "        col_1 = fd.pop('company')\n",
    "        col_2 = fd.pop('ticker')        \n",
    "        col_3 = fd.pop('my_score')\n",
    "        col_4 = fd.pop('sentiment_score')\n",
    "        col_5 = fd.pop('rs_rating')\n",
    "        col_7 = fd.pop('analyst_recom')                    \n",
    "        col_8 = fd.pop('returns_multiple')\n",
    "        col_9 = fd.pop('price')\n",
    "        col_10 = fd.pop('target_price')\n",
    "        fd.insert(0, 'target_price', col_10)   \n",
    "        fd.insert(0, 'price', col_9)   \n",
    "        fd.insert(0, 'returns_multiple', col_8)           \n",
    "        fd.insert(0, 'analyst_recom', col_7)                \n",
    "        fd.insert(0, 'rs_rating', col_5)           \n",
    "        fd.insert(0, 'sentiment_score', col_4)     \n",
    "        fd.insert(0, 'my_score', col_3)  \n",
    "        fd.insert(0, 'ticker', col_2)\n",
    "        fd.insert(0, 'company', col_1)\n",
    "        return fd\n",
    "    \n",
    "\n",
    "    def trim_1(fd):        \n",
    "        fd = pd.DataFrame(fd)\n",
    "        q_1 = fd['returns_multiple'].quantile(0.1)\n",
    "        q_2 = fd['returns_multiple'].quantile(0.2)\n",
    "        q_3 = fd['returns_multiple'].quantile(0.3)\n",
    "        q_4 = fd['returns_multiple'].quantile(0.4)\n",
    "        q_5 = fd['returns_multiple'].quantile(0.5)\n",
    "        q_6 = fd['returns_multiple'].quantile(0.6)\n",
    "        q_7 = fd['returns_multiple'].quantile(0.7)\n",
    "        q_8 = fd['returns_multiple'].quantile(0.8)\n",
    "        q_9 = fd['returns_multiple'].quantile(0.9)        \n",
    "        for r in fd['returns_multiple']:\n",
    "            if r <= q_1:\n",
    "                fd['my_score'] * 1.01\n",
    "            if r > q_1 and r <= q_2:\n",
    "                fd['my_score'] * 1.02\n",
    "            if r > q_2 and r <= q_3:\n",
    "                fd['my_score'] * 1.03\n",
    "            if r > q_3 and r <= q_4:\n",
    "                fd['my_score'] * 1.04\n",
    "            if r > q_4 and r <= q_5:\n",
    "                fd['my_score'] * 1.05\n",
    "            if r > q_5 and r <= q_6:\n",
    "                fd['my_score'] * 1.06\n",
    "            if r > q_6 and r <= q_7:\n",
    "                fd['my_score'] * 1.07\n",
    "            if r > q_7 and r <= q_8:\n",
    "                fd['my_score'] * 1.08\n",
    "            if r > q_8 and r <= q_9:\n",
    "                fd['my_score'] * 1.09\n",
    "            if r > q_9:\n",
    "                fd['my_score'] * 1.10\n",
    "        fd_len = len(fd['ticker'])\n",
    "        print(f'[5] Recommender Stage #05 - [Total Passed == {fd_len}]')                \n",
    "        return fd\n",
    "    \n",
    "    \n",
    "    def trim_2(fd):\n",
    "        std1 = fd['relative_strength_index_14'].std()\n",
    "        fd = pd.DataFrame(fd[fd['relative_strength_index_14'] <= (70.0 - (std1 * 1.0))])\n",
    "        # fd = pd.DataFrame(fd[fd['relative_strength_index_14'] <= 60.0])\n",
    "        # fd = pd.DataFrame(fd[fd['relative_strength_index_14'] >= 30.0])\n",
    "        fd_len = len(fd['ticker'])\n",
    "        print(f'[5] Stage #05 - Total Passed [[ FINAL ]] = [{fd_len}]]')        \n",
    "        return fd.sort_values('my_score', ascending=False).round(2)\n",
    "    \n",
    "\n",
    "    fd = pd.DataFrame(data).reset_index()\n",
    "    fd = re_order_cols(fd)                         \n",
    "    fd = trim_1(fd)           \n",
    "    # fd = trim_2(fd)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.DataFrame(run_rec_5(df_4)).fillna(0.0)\n",
    "print(df_5.shape)\n",
    "df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_pickle(saveRec / \"recommender_05_return_dataFrame.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.head(30).round(2).sort_values('my_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('roy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d77fb98bc974d9140e1d63aa372f5a172212fa8a9aef6a9ab24d898563ca3b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
